{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b2841eb-5141-4dd7-9b92-a06e8eb113b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['damage', 'no_damage']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Path to your cloned repo folder\n",
    "data_dir = \"coe379L-sp25/datasets/unit03/Project3\"  # or use the full path\n",
    "\n",
    "# Image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Wrap in DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Print classes\n",
    "print(\"Classes:\", dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a84d58c6-78b8-4666-806b-cc43ee1ac0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "damage: 14170 images\n",
      "no_damage: 7152 images\n",
      "Sample image size: (128, 128)\n",
      "Most common image shapes:\n",
      "(128, 128): 21322 images\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "# Count total images per class\n",
    "for cls in dataset.classes:\n",
    "    folder = os.path.join(data_dir, cls)\n",
    "    print(f\"{cls}: {len(os.listdir(folder))} images\")\n",
    "\n",
    "# Check size of a sample image\n",
    "sample_path = os.path.join(data_dir, dataset.classes[0], os.listdir(os.path.join(data_dir, dataset.classes[0]))[0])\n",
    "img = Image.open(sample_path)\n",
    "print(f\"Sample image size: {img.size}\")\n",
    "\n",
    "shape_counter = Counter()\n",
    "\n",
    "for cls in dataset.classes:\n",
    "    folder = os.path.join(data_dir, cls)\n",
    "    for img_name in os.listdir(folder):\n",
    "        path = os.path.join(folder, img_name)\n",
    "        try:\n",
    "            with Image.open(path) as img:\n",
    "                shape_counter[img.size] += 1\n",
    "        except:\n",
    "            pass  \n",
    "\n",
    "print(\"Most common image shapes:\")\n",
    "for shape, count in shape_counter.most_common(5):\n",
    "    print(f\"{shape}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e5292d5-d4a6-4d0a-a53d-4f5ad0db2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "# Get all indices and labels\n",
    "indices = list(range(len(dataset)))\n",
    "labels = [sample[1] for sample in dataset.samples]\n",
    "\n",
    "# Split: 80% train, 10% val, 10% test\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    indices, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, test_size=0.5, stratify=[labels[i] for i in temp_idx], random_state=42\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a108b95-7a6f-4577-b4ae-cad11e80e6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 17057\n",
      "Validation set size: 2132\n",
      "Test set size: 2133\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(val_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97537b28-2267-488b-81a3-45015c68e1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b85a6b53-12ba-4b99-b9ef-a62480ab57cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1/10\n",
      "  ‚úÖ Train Loss: 0.7417 | Acc: 0.7286\n",
      "  üîç Val   Loss: 0.5229 | Acc: 0.7575\n",
      "Epoch 2/10\n",
      "  ‚úÖ Train Loss: 0.4831 | Acc: 0.7824\n",
      "  üîç Val   Loss: 0.4831 | Acc: 0.7641\n",
      "Epoch 3/10\n",
      "  ‚úÖ Train Loss: 0.4489 | Acc: 0.7983\n",
      "  üîç Val   Loss: 0.5682 | Acc: 0.7265\n",
      "Epoch 4/10\n",
      "  ‚úÖ Train Loss: 0.4324 | Acc: 0.8095\n",
      "  üîç Val   Loss: 0.7094 | Acc: 0.6698\n",
      "Epoch 5/10\n",
      "  ‚úÖ Train Loss: 0.4305 | Acc: 0.8055\n",
      "  üîç Val   Loss: 0.4605 | Acc: 0.7885\n",
      "Epoch 6/10\n",
      "  ‚úÖ Train Loss: 0.4033 | Acc: 0.8276\n",
      "  üîç Val   Loss: 0.4728 | Acc: 0.7767\n",
      "Epoch 7/10\n",
      "  ‚úÖ Train Loss: 0.3861 | Acc: 0.8334\n",
      "  üîç Val   Loss: 0.4497 | Acc: 0.7922\n",
      "Epoch 8/10\n",
      "  ‚úÖ Train Loss: 0.3689 | Acc: 0.8432\n",
      "  üîç Val   Loss: 0.6224 | Acc: 0.7087\n",
      "Epoch 9/10\n",
      "  ‚úÖ Train Loss: 0.3598 | Acc: 0.8458\n",
      "  üîç Val   Loss: 0.5000 | Acc: 0.7875\n",
      "Epoch 10/10\n",
      "  ‚úÖ Train Loss: 0.3431 | Acc: 0.8568\n",
      "  üîç Val   Loss: 0.4762 | Acc: 0.7842\n",
      "\n",
      "üéØ Test Accuracy: 0.8148\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "class DenseANN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseANN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 128 * 3, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = DenseANN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ------------------------------\n",
    "# üîÅ Training & Evaluation Functions\n",
    "# ------------------------------\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Run Training Loop\n",
    "# ------------------------------\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  ‚úÖ Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "    print(f\"  üîç Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# üß™ Final Test Accuracy\n",
    "# ------------------------------\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f\"\\nüéØ Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fda4a5b-c1de-4cf5-8618-f628146321da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  ‚úÖ Train Loss: 0.3879 | Acc: 0.8261\n",
      "  üîç Val   Loss: 0.2225 | Acc: 0.9132\n",
      "Epoch 2/20\n",
      "  ‚úÖ Train Loss: 0.2635 | Acc: 0.9035\n",
      "  üîç Val   Loss: 0.2081 | Acc: 0.9226\n",
      "Epoch 3/20\n",
      "  ‚úÖ Train Loss: 0.2094 | Acc: 0.9239\n",
      "  üîç Val   Loss: 0.2219 | Acc: 0.9146\n",
      "Epoch 4/20\n",
      "  ‚úÖ Train Loss: 0.1834 | Acc: 0.9296\n",
      "  üîç Val   Loss: 0.1924 | Acc: 0.9306\n",
      "Epoch 5/20\n",
      "  ‚úÖ Train Loss: 0.1503 | Acc: 0.9414\n",
      "  üîç Val   Loss: 0.1697 | Acc: 0.9339\n",
      "Epoch 6/20\n",
      "  ‚úÖ Train Loss: 0.1427 | Acc: 0.9458\n",
      "  üîç Val   Loss: 0.1838 | Acc: 0.9292\n",
      "Epoch 7/20\n",
      "  ‚úÖ Train Loss: 0.1347 | Acc: 0.9496\n",
      "  üîç Val   Loss: 0.1892 | Acc: 0.9362\n",
      "Epoch 8/20\n",
      "  ‚úÖ Train Loss: 0.1114 | Acc: 0.9581\n",
      "  üîç Val   Loss: 0.1510 | Acc: 0.9409\n",
      "Epoch 9/20\n",
      "  ‚úÖ Train Loss: 0.1005 | Acc: 0.9617\n",
      "  üîç Val   Loss: 0.1808 | Acc: 0.9306\n",
      "Epoch 10/20\n",
      "  ‚úÖ Train Loss: 0.0914 | Acc: 0.9639\n",
      "  üîç Val   Loss: 0.1629 | Acc: 0.9395\n",
      "Epoch 11/20\n",
      "  ‚úÖ Train Loss: 0.0800 | Acc: 0.9707\n",
      "  üîç Val   Loss: 0.1640 | Acc: 0.9348\n",
      "‚èπÔ∏è Early stopping at epoch 11\n",
      "\n",
      "üéØ Final Test Accuracy: 0.9498\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ------------------------------\n",
    "# üß† LeNet-5 with Dropout\n",
    "# ------------------------------\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)     # ‚Üí (6, 124, 124)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)                        # ‚Üí (6, 62, 62)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)   # ‚Üí (16, 58, 58) ‚Üí pool ‚Üí (16, 29, 29)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 29 * 29, 120)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------------\n",
    "# ‚öôÔ∏è Setup\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# ------------------------------\n",
    "# Training / Evaluation Functions\n",
    "# ------------------------------\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# üß† Early Stopping Logic\n",
    "# ------------------------------\n",
    "EPOCHS = 20\n",
    "patience = 3\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  ‚úÖ Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "    print(f\"  üîç Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_lenet5_model.pth\")  # Save best model\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# ------------------------------\n",
    "# üß™ Load Best Model & Test\n",
    "# ------------------------------\n",
    "model.load_state_dict(torch.load(\"best_lenet5_model.pth\"))\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f\"\\nüéØ Final Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd5dd8b-9e87-4308-8a5f-d36c4e806fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  ‚úÖ Train Loss: 0.3393 | Acc: 0.8560\n",
      "  üîç Val   Loss: 0.3051 | Acc: 0.8780\n",
      "Epoch 2/10\n",
      "  ‚úÖ Train Loss: 0.1993 | Acc: 0.9238\n",
      "  üîç Val   Loss: 0.1821 | Acc: 0.9259\n",
      "Epoch 3/10\n",
      "  ‚úÖ Train Loss: 0.1448 | Acc: 0.9438\n",
      "  üîç Val   Loss: 0.1498 | Acc: 0.9414\n",
      "Epoch 4/10\n",
      "  ‚úÖ Train Loss: 0.1110 | Acc: 0.9597\n",
      "  üîç Val   Loss: 0.1453 | Acc: 0.9442\n",
      "Epoch 5/10\n",
      "  ‚úÖ Train Loss: 0.0787 | Acc: 0.9706\n",
      "  üîç Val   Loss: 0.1527 | Acc: 0.9423\n",
      "Epoch 6/10\n",
      "  ‚úÖ Train Loss: 0.0542 | Acc: 0.9818\n",
      "  üîç Val   Loss: 0.2332 | Acc: 0.9353\n",
      "Epoch 7/10\n",
      "  ‚úÖ Train Loss: 0.0490 | Acc: 0.9832\n",
      "  üîç Val   Loss: 0.1642 | Acc: 0.9423\n",
      "Epoch 8/10\n",
      "  ‚úÖ Train Loss: 0.0340 | Acc: 0.9889\n",
      "  üîç Val   Loss: 0.2342 | Acc: 0.9315\n",
      "Epoch 9/10\n",
      "  ‚úÖ Train Loss: 0.0500 | Acc: 0.9826\n",
      "  üîç Val   Loss: 0.2443 | Acc: 0.9329\n",
      "Epoch 10/10\n",
      "  ‚úÖ Train Loss: 0.0217 | Acc: 0.9928\n",
      "  üîç Val   Loss: 0.2257 | Acc: 0.9456\n",
      "\n",
      "üéØ Final Test Accuracy: 0.9466\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ------------------------------\n",
    "# üß† Alternate LeNet-5 CNN\n",
    "# ------------------------------\n",
    "class AlternateLeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlternateLeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)     # (3,128,128) -> (6,128,128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)          # -> (6,64,64)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=2)    # -> (16,64,64)\n",
    "        # pool again ‚Üí (16,32,32)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 32 * 32, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------------\n",
    "# ‚öôÔ∏è Setup\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AlternateLeNet5().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# ------------------------------\n",
    "# üîÅ Training / Evaluation Functions\n",
    "# ------------------------------\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), total_correct / len(loader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Training Loop\n",
    "# ------------------------------\n",
    "EPOCHS = 10  # You can increase to 20+ if you're not using early stopping\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  ‚úÖ Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "    print(f\"  üîç Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# üß™ Final Test Evaluation\n",
    "# ------------------------------\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f\"\\nüéØ Final Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82f46ce7-ce96-4df1-bee6-ec76c6024a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  ‚úÖ Train Loss: 0.3880 | Acc: 0.8304\n",
      "  üîç Val   Loss: 0.2317 | Acc: 0.9099\n",
      "Epoch 2/30\n",
      "  ‚úÖ Train Loss: 0.2581 | Acc: 0.9085\n",
      "  üîç Val   Loss: 0.3018 | Acc: 0.8912\n",
      "Epoch 3/30\n",
      "  ‚úÖ Train Loss: 0.2211 | Acc: 0.9170\n",
      "  üîç Val   Loss: 0.1718 | Acc: 0.9334\n",
      "Epoch 4/30\n",
      "  ‚úÖ Train Loss: 0.2011 | Acc: 0.9244\n",
      "  üîç Val   Loss: 0.1835 | Acc: 0.9296\n",
      "Epoch 5/30\n",
      "  ‚úÖ Train Loss: 0.1910 | Acc: 0.9282\n",
      "  üîç Val   Loss: 0.1518 | Acc: 0.9423\n",
      "Epoch 6/30\n",
      "  ‚úÖ Train Loss: 0.1819 | Acc: 0.9305\n",
      "  üîç Val   Loss: 0.1836 | Acc: 0.9231\n",
      "Epoch 7/30\n",
      "  ‚úÖ Train Loss: 0.1707 | Acc: 0.9362\n",
      "  üîç Val   Loss: 0.1390 | Acc: 0.9447\n",
      "Epoch 8/30\n",
      "  ‚úÖ Train Loss: 0.1658 | Acc: 0.9368\n",
      "  üîç Val   Loss: 0.1365 | Acc: 0.9456\n",
      "Epoch 9/30\n",
      "  ‚úÖ Train Loss: 0.1602 | Acc: 0.9391\n",
      "  üîç Val   Loss: 0.1749 | Acc: 0.9226\n",
      "Epoch 10/30\n",
      "  ‚úÖ Train Loss: 0.1554 | Acc: 0.9401\n",
      "  üîç Val   Loss: 0.1347 | Acc: 0.9465\n",
      "Epoch 11/30\n",
      "  ‚úÖ Train Loss: 0.1387 | Acc: 0.9449\n",
      "  üîç Val   Loss: 0.1503 | Acc: 0.9447\n",
      "Epoch 12/30\n",
      "  ‚úÖ Train Loss: 0.1406 | Acc: 0.9453\n",
      "  üîç Val   Loss: 0.1170 | Acc: 0.9536\n",
      "Epoch 13/30\n",
      "  ‚úÖ Train Loss: 0.1340 | Acc: 0.9467\n",
      "  üîç Val   Loss: 0.1154 | Acc: 0.9522\n",
      "Epoch 14/30\n",
      "  ‚úÖ Train Loss: 0.1367 | Acc: 0.9455\n",
      "  üîç Val   Loss: 0.1132 | Acc: 0.9526\n",
      "Epoch 15/30\n",
      "  ‚úÖ Train Loss: 0.1206 | Acc: 0.9506\n",
      "  üîç Val   Loss: 0.1049 | Acc: 0.9559\n",
      "Epoch 16/30\n",
      "  ‚úÖ Train Loss: 0.1245 | Acc: 0.9509\n",
      "  üîç Val   Loss: 0.1190 | Acc: 0.9493\n",
      "Epoch 17/30\n",
      "  ‚úÖ Train Loss: 0.1227 | Acc: 0.9525\n",
      "  üîç Val   Loss: 0.1026 | Acc: 0.9620\n",
      "Epoch 18/30\n",
      "  ‚úÖ Train Loss: 0.1134 | Acc: 0.9535\n",
      "  üîç Val   Loss: 0.0903 | Acc: 0.9629\n",
      "Epoch 19/30\n",
      "  ‚úÖ Train Loss: 0.1198 | Acc: 0.9525\n",
      "  üîç Val   Loss: 0.1587 | Acc: 0.9329\n",
      "Epoch 20/30\n",
      "  ‚úÖ Train Loss: 0.1206 | Acc: 0.9517\n",
      "  üîç Val   Loss: 0.1027 | Acc: 0.9526\n",
      "Epoch 21/30\n",
      "  ‚úÖ Train Loss: 0.1115 | Acc: 0.9552\n",
      "  üîç Val   Loss: 0.0988 | Acc: 0.9625\n",
      "Epoch 22/30\n",
      "  ‚úÖ Train Loss: 0.1013 | Acc: 0.9598\n",
      "  üîç Val   Loss: 0.0888 | Acc: 0.9676\n",
      "Epoch 23/30\n",
      "  ‚úÖ Train Loss: 0.0976 | Acc: 0.9625\n",
      "  üîç Val   Loss: 0.1001 | Acc: 0.9597\n",
      "Epoch 24/30\n",
      "  ‚úÖ Train Loss: 0.0932 | Acc: 0.9614\n",
      "  üîç Val   Loss: 0.0981 | Acc: 0.9587\n",
      "Epoch 25/30\n",
      "  ‚úÖ Train Loss: 0.0953 | Acc: 0.9625\n",
      "  üîç Val   Loss: 0.0910 | Acc: 0.9601\n",
      "Epoch 26/30\n",
      "  ‚úÖ Train Loss: 0.0879 | Acc: 0.9650\n",
      "  üîç Val   Loss: 0.0830 | Acc: 0.9667\n",
      "Epoch 27/30\n",
      "  ‚úÖ Train Loss: 0.0865 | Acc: 0.9664\n",
      "  üîç Val   Loss: 0.0817 | Acc: 0.9662\n",
      "Epoch 28/30\n",
      "  ‚úÖ Train Loss: 0.0937 | Acc: 0.9639\n",
      "  üîç Val   Loss: 0.0801 | Acc: 0.9672\n",
      "Epoch 29/30\n",
      "  ‚úÖ Train Loss: 0.0848 | Acc: 0.9668\n",
      "  üîç Val   Loss: 0.0803 | Acc: 0.9672\n",
      "Epoch 30/30\n",
      "  ‚úÖ Train Loss: 0.0794 | Acc: 0.9679\n",
      "  üîç Val   Loss: 0.0829 | Acc: 0.9648\n",
      "\n",
      "üéØ Final Test Accuracy: 0.9672\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ------------------------------\n",
    "# üß† Define Optimized Alternate LeNet-5\n",
    "# ------------------------------\n",
    "class OptimizedAlternateLeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OptimizedAlternateLeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=2)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 32 * 32, 120)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# ------------------------------\n",
    "# üîÅ Data Augmentation & Reload Data\n",
    "# ------------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# Reload dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Split\n",
    "indices = list(range(len(dataset)))\n",
    "labels = [sample[1] for sample in dataset.samples]\n",
    "\n",
    "train_idx, temp_idx = train_test_split(indices, test_size=0.2, stratify=labels, random_state=42)\n",
    "val_idx, test_idx = train_test_split(temp_idx, test_size=0.5, stratify=[labels[i] for i in temp_idx], random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ------------------------------\n",
    "# ‚öôÔ∏è Training Setup\n",
    "# ------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = OptimizedAlternateLeNet5().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# ------------------------------\n",
    "# üîÅ Training & Evaluation Functions\n",
    "# ------------------------------\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "# ------------------------------\n",
    "# üöÄ Training Loop with Early Stopping\n",
    "# ------------------------------\n",
    "EPOCHS = 30\n",
    "best_val_loss = float('inf')\n",
    "patience = 4\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"  ‚úÖ Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
    "    print(f\"  üîç Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"optimized_lenet5.pth\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"‚èπÔ∏è Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# ------------------------------\n",
    "# üß™ Final Test Accuracy\n",
    "# ------------------------------\n",
    "model.load_state_dict(torch.load(\"optimized_lenet5.pth\"))\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion)\n",
    "print(f\"\\nüéØ Final Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c9e406f-a24d-4c33-a16e-0d3b8778c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"optimized_lenet5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6311a74-fbcd-46d4-956f-a74900832f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
